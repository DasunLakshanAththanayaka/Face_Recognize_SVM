{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02ae74",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2469891362.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport cv2|\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# load image one by one \n",
    "# convert to gray scale\n",
    "# face detection -face crop \n",
    "# 50 *50  resize \n",
    "# flatten 2500\n",
    "#dataset append\n",
    "\n",
    "data_path='train_data_2'\n",
    "labels=os.listdir(data_path)\n",
    "print(labels)\n",
    "categories=np.arange(len(labels))\n",
    "print(categories)\n",
    "categories_dict=dict(zip(labels,categories))\n",
    "print(categories_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03edf0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\asus\\anaconda3\\envs\\testone\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a16bb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n",
      "If you accept this cropped face press y or n:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m cv2.imshow(\u001b[33m'\u001b[39m\u001b[33mcropped_face\u001b[39m\u001b[33m'\u001b[39m,cropped_face)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mIf you accept this cropped face press y or n:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m k=\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(k==\u001b[32m127\u001b[39m):\n\u001b[32m     31\u001b[39m     cropped_face=cv2.resize((cropped_face,(\u001b[32m50\u001b[39m,\u001b[32m50\u001b[39m)))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_classifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "data=[]\n",
    "target=[]\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    imgs_path=os.path.join(data_path,label)\n",
    "    # print(imgs_path)\n",
    "    img_names=os.listdir(imgs_path)\n",
    "    # print(img_names)\n",
    "    # print(\"---------------------------------------\")\n",
    "    for img_name in img_names:\n",
    "        img_path=os.path.join(imgs_path,img_name)\n",
    "        # print(img_path)\n",
    "        img=cv2.imread(img_path)\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_classifier.detectMultiScale(gray)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cropped_face=gray[y:y+h,x:x+w]\n",
    "            cv2.imshow('cropped_face',cropped_face)\n",
    "\n",
    "            print('If you accept this cropped face press y or n:')\n",
    "\n",
    "            k=cv2.waitKey(0)\n",
    "\n",
    "            if(k==127):\n",
    "                cropped_face=cv2.resize((cropped_face,(50,50)))\n",
    "                data.append(cropped_face)\n",
    "                target.append(categories_dict[label])\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18c68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
